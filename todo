
best way to configure LMS global settings. 
re-think recall and precision - what is our metric
revisit all the possible variables (replicas, max failures, managedGet, etc.)


### experiment

store successes, failures, 

### fixes

* UDS should be a torus not a finite universe-- but since we're not moving
  any nodes right now it doesn't affect our results. 
* LMS get should have multiple probes, not at the fog layer. 
* fog node bufferAdd() should not use a list for items w say key
* if fog node is going to have a cache then when it executes a query it
  should check its own cache first.  

### features

* lifetime and radius at fog layer
* time framework
* adaptive protocol - adjust replicas as needed. 
* digests, subscriptions
* when a new guy is added, he should get his own neighbours, but then other
  nodes' neighbours should update asynchronously. 
* also, the node should update its own neighbours. 
* lifetime management should happen in the fog layer. 
* radius management - design (limit protocol?)

### extensions to/experiments with LMS?

* original model does not allow adding of neighbours - how does apartive
  protocol perform in a more dynamic environment?
* LMS with radius-constrained storage
* shared key space? (ie tags not keys) - LMS is designed around unique keys,
  but in LMS the keys are what we query on. we want a system queriable by tag,
  but tags are not unique. also by content and 
* LMS over different densities of topology ('node congestion')
* behaviour with varying buffer sizes - can show it converges to some avg.? 
* also in LMS paper i don't think nodes getting 'full' (buffer) is analyzed

### report

Show performance of LMS as number of nodes, broadcast radius, hops, varies over time

--> to note:

LMS where the data is a message and its key or keys are its tag(s). 
multiple messages with the same tag - what happens
physical space - edges - wraparound?
currently tags are arbitrary. 

decision not to explore key-space collisions or general network congestion
(many messages) since that is an extension and first we want to demo
correctness. 

other factors: num replicas, num probes, max failures, random walk length,
length of deterministic walk to the local minima

how performance degrades when density is too high... 


LMS - with high sparsity, PUT recall is poor because there's not enough local minima. 

get never performas as well as put, which makes sense
